import os
import streamlit as st
from dotenv import load_dotenv
from hybrid_search import SearchEngine, FaissStore
from rag_chain import RAGChain

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –ª–∏—á–Ω–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
    st.session_state.messages = []


@st.cache_resource
def load_search_engine():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    try:
        store = FaissStore(index_path="faiss.index", meta_path="faiss_meta.npy")
        search_engine = SearchEngine(store, use_reranker=False)
        return search_engine
    except FileNotFoundError as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        st.info("""
        **–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∏–Ω–¥–µ–∫—Å–∞:**
        
        1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã `faiss.index` –∏ `faiss_meta.npy` —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        2. –ï—Å–ª–∏ –∏—Ö –Ω–µ—Ç, –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é:
        
        ```bash
        python faiss_vectorization.py --folder files --embedder sbert
        ```
        """)
        return None


@st.cache_resource
def load_rag_chain(_search_engine):
    """–°–æ–∑–¥–∞–µ—Ç RAG —Ü–µ–ø–æ—á–∫—É —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    if _search_engine is None:
        return None
    
    try:
        rag_chain = RAGChain(
            search_engine=_search_engine,
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=1000
        )
        return rag_chain
    except RuntimeError as e:
        st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG —Ü–µ–ø–æ—á–∫–∏: {e}")
        st.info("""
        **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:**
        
        1. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è `OPENAI_API_KEY`
        2. API –∫–ª—é—á –≤–∞–ª–∏–¥–µ–Ω –∏ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ gpt-4o-mini
        """)
        return None


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üéì AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –ª–∏—á–Ω–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è API –∫–ª—é—á–∞
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            st.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            st.info("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env")
        else:
            st.success("‚úÖ API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
        
        st.markdown("---")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
        st.subheader("üîç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")
        top_k = st.slider(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (top_k)",
            min_value=3,
            max_value=10,
            value=5,
            step=1,
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
        )
        
        st.markdown("---")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
        st.subheader("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ")
        st.markdown("""
        –≠—Ç–æ—Ç AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–º–æ–≥–∞–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞–º –Ω–∞—Ö–æ–¥–∏—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã 
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∑–∞–∫–æ–Ω—ã, –ø—Ä–∏–∫–∞–∑—ã, –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è).
        
        **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
        - –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (FAISS + BM25)
        - RAG (Retrieval-Augmented Generation)
        - GPT-3.5-turbo
        """)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    search_engine = load_search_engine()
    rag_chain = load_rag_chain(search_engine)
    
    if search_engine is None or rag_chain is None:
        st.stop()
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å —á–∞—Ç–∞
    st.subheader("üí¨ –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å")
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            if message["role"] == "assistant" and "sources" in message:
                with st.expander("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                    for i, source in enumerate(message["sources"], 1):
                        st.markdown(f"""
                        **–ò—Å—Ç–æ—á–Ω–∏–∫ {i}:**
                        - –î–æ–∫—É–º–µ–Ω—Ç: `{source.get('doc_id', 'N/A')}`
                        - –†–∞–∑–¥–µ–ª: {source.get('section', 'N/A')}
                        - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source.get('score', 0):.4f}
                        """)
    
    # –ü–æ–ª–µ –≤–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞
    if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å..."):
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        with st.chat_message("assistant"):
            with st.spinner("üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
                try:
                    result = rag_chain.generate_answer(
                        query=prompt,
                        top_k=top_k,
                        use_reranker=False
                    )
                    
                    answer = result['answer']
                    sources = result['sources']
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Ç–≤–µ—Ç
                    st.markdown(answer)
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                    if sources:
                        with st.expander("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"):
                            for i, source in enumerate(sources, 1):
                                st.markdown(f"""
                                **–ò—Å—Ç–æ—á–Ω–∏–∫ {i}:**
                                - –î–æ–∫—É–º–µ–Ω—Ç: `{source.get('doc_id', 'N/A')}`
                                - –†–∞–∑–¥–µ–ª: {source.get('section', 'N/A')}
                                - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source.get('score', 0):.4f}
                                """)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": answer,
                        "sources": sources
                    })
                    
                except Exception as e:
                    error_msg = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": error_msg
                    })
    
    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
    if st.session_state.messages:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", type="secondary"):
            st.session_state.messages = []
            st.rerun()


if __name__ == "__main__":
    main()

